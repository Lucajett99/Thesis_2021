\babel@toc {italian}{}
\babel@toc {italian}{}
\contentsline {chapter}{\numberline {1}Introduzione}{3}{}%
\contentsline {chapter}{\numberline {2}AI in Radiology}{4}{}%
\contentsline {section}{\numberline {2.1}Overview}{4}{}%
\contentsline {section}{\numberline {2.2}Workflow}{5}{}%
\contentsline {subsection}{\numberline {2.2.1}Raccolta dei dati}{5}{}%
\contentsline {subsubsection}{Approvazione istituzionale}{6}{}%
\contentsline {subsection}{\numberline {2.2.2}Cura dei dati}{6}{}%
\contentsline {subsubsection}{Anonimizzazione dei dati}{7}{}%
\contentsline {subsubsection}{Esplorazione dei dati e controllo qualità}{7}{}%
\contentsline {subsubsection}{Etichettatura dei dati per l'addestramento}{7}{}%
\contentsline {subsubsection}{Esclusione dei dati}{7}{}%
\contentsline {subsubsection}{Strategie di campionamento dei set di dati}{8}{}%
\contentsline {subsubsection}{Transfer learning}{8}{}%
\contentsline {subsection}{\numberline {2.2.3}Creazione del modello}{9}{}%
\contentsline {subsubsection}{Encoder}{10}{}%
\contentsline {subsubsection}{Decoder}{10}{}%
\contentsline {subsection}{\numberline {2.2.4}Formazione del modello}{11}{}%
\contentsline {subsection}{\numberline {2.2.5}Analisi e metriche}{11}{}%
\contentsline {subsection}{\numberline {2.2.6}Distribuzione}{12}{}%
\contentsline {section}{\numberline {2.3}Analisi e conclusioni}{13}{}%
\contentsline {subsection}{\numberline {2.3.1}I dati}{13}{}%
\contentsline {subsection}{\numberline {2.3.2}Il modello}{14}{}%
\contentsline {subsubsection}{Tipi di apprendimento}{15}{}%
\contentsline {subsection}{\numberline {2.3.3}Conclusioni}{17}{}%
\contentsline {chapter}{\numberline {3}Demand forecasting}{18}{}%
\contentsline {section}{\numberline {3.1}Overview}{18}{}%
\contentsline {section}{\numberline {3.2}Workflow}{19}{}%
\contentsline {subsection}{\numberline {3.2.1}Raccolta dati}{19}{}%
\contentsline {subsection}{\numberline {3.2.2}Comprensione e preelaborazione dei dati}{20}{}%
\contentsline {subsubsection}{Parametri di qualità dei dati}{20}{}%
\contentsline {subsubsection}{Preelaborazione dei dati}{20}{}%
\contentsline {subsection}{\numberline {3.2.3}Costruzione del modello}{21}{}%
\contentsline {subsubsection}{Perceptron multistrato (MLP)}{22}{}%
\contentsline {subsubsection}{Rete neurale bayesiana (BNN)}{23}{}%
\contentsline {subsubsection}{Reti neurali di regressione generalizzata (GRNN)}{24}{}%
\contentsline {subsubsection}{Regressione K-Nearest Neighbor (KNN)}{25}{}%
\contentsline {subsubsection}{Regressione del vettore di supporto (SVR)}{25}{}%
\contentsline {subsubsection}{Rete Neurale Ricorrente (RNN)}{26}{}%
\contentsline {subsubsection}{Rete neurale di memoria a lungo termine (LSTM)}{26}{}%
\contentsline {subsection}{\numberline {3.2.4}Formazione del modello}{27}{}%
\contentsline {subsection}{\numberline {3.2.5}Validazione del modelllo}{27}{}%
\contentsline {subsection}{\numberline {3.2.6}Miglioramento}{27}{}%
\contentsline {subsection}{\numberline {3.2.7}Distribuzione}{28}{}%
\contentsline {section}{\numberline {3.3}Analisi e conclusioni}{28}{}%
\contentsline {subsection}{\numberline {3.3.1}I dati}{28}{}%
\contentsline {subsection}{\numberline {3.3.2}Il modello}{30}{}%
\contentsline {subsection}{\numberline {3.3.3}Conclusioni}{32}{}%
\contentsline {chapter}{\numberline {4}Frameworks}{33}{}%
\contentsline {section}{\numberline {4.1}MetaFlow}{33}{}%
\contentsline {subsection}{\numberline {4.1.1}Vantaggi}{34}{}%
\contentsline {section}{\numberline {4.2}ZenML}{35}{}%
\contentsline {subsection}{\numberline {4.2.1}Problemi risolti da ZenML}{35}{}%
\contentsline {subsection}{\numberline {4.2.2}Vantaggi}{36}{}%
\contentsline {section}{\numberline {4.3}MLRun}{37}{}%
\contentsline {subsection}{\numberline {4.3.1}Vantaggi}{37}{}%
\contentsline {chapter}{\numberline {5}Conclusioni}{40}{}%
\contentsline {chapter}{Appendices}{42}{}%
\contentsline {section}{\numberline {.1}Recurrent neural network}{43}{}%
\contentsline {section}{\numberline {.2}Convolutional neural network}{43}{}%
\contentsline {section}{\numberline {.3}Long-Short Term Memory}{43}{}%
\contentsline {section}{\numberline {.4}Gated Recurrent Units (GRU)}{44}{}%
\contentsline {section}{\numberline {.5}Natural language processing (NLP)}{44}{}%
\contentsline {section}{\numberline {.6}Neuro-linguistic programming (PNL)}{44}{}%
\contentsline {section}{\numberline {.7}Power Trasformation (Box-Cox)}{44}{}%
\contentsline {section}{\numberline {.8}Docker}{45}{}%
\contentsline {section}{\numberline {.9}Kubernetes}{45}{}%
\contentsline {section}{\numberline {.10}Exponential Smoothing di Holt Winter}{45}{}%
\contentsline {section}{\numberline {.11}ARIMA/SARIMA}{45}{}%
\contentsline {section}{\numberline {.12}Root-mean-square deviation (RMSD)}{46}{}%
\contentsline {section}{\numberline {.13}Mean absolute percentage error (MAPE)}{46}{}%
\contentsline {section}{\numberline {.14}DICOM}{47}{}%
\contentsline {section}{\numberline {.15}PACS}{47}{}%
