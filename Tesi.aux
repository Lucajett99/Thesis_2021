\relax 
\providecommand\babel@aux[2]{}
\@nameuse{bbl@beforestart}
\babel@aux{italian}{}
\babel@aux{italian}{}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduzione}{3}{}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}AI in Radiology}{4}{}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Overview}{4}{}\protected@file@percent }
\citation{singh2019chest}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Workflow}{5}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Raccolta dei dati}{5}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Approvazione istituzionale}{6}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Cura dei dati}{6}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Anonimizzazione dei dati}{7}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Esplorazione dei dati e controllo qualità}{7}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Etichettatura dei dati per l'addestramento}{7}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Esclusione dei dati}{7}{}\protected@file@percent }
\citation{singh2019chest}
\citation{pennington2014glove}
\citation{zhang2018learning}
\@writefile{toc}{\contentsline {subsubsection}{Strategie di campionamento dei set di dati}{8}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Transfer learning}{8}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.3}Creazione del modello}{9}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Schema a blocchi di un framework encoder-decoder\relax }}{9}{}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:econder-decoder}{{2.1}{9}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Un framework Encoder-Decoder per la generazione di referti radiologici da immagini edical. t = 0, · · · , t = N rappresenta le iterazioni della ricorrenza LSTM.\relax }}{10}{}\protected@file@percent }
\newlabel{fig:LSTM}{{2.2}{10}}
\@writefile{toc}{\contentsline {subsubsection}{Encoder}{10}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Decoder}{10}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.4}Formazione del modello}{11}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.5}Analisi e metriche}{11}{}\protected@file@percent }
\citation{montagnon2020deep}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Schema schematico di una cella LSTM\relax }}{12}{}\protected@file@percent }
\newlabel{fig:LSTM-schema}{{2.3}{12}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.6}Distribuzione}{12}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Analisi e conclusioni}{13}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}I dati}{13}{}\protected@file@percent }
\citation{banerjee2019comparative}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}Il modello}{14}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Divisione del set di dati in set di dati di addestramento, convalida e test. Si consiglia di eseguire la suddivisione all'inizio del flusso di lavoro, mantenendo i dati di test nascosti al modello fino alla valutazione finale delle prestazioni\relax }}{15}{}\protected@file@percent }
\newlabel{fig:data-sampling-radiology}{{2.4}{15}}
\@writefile{toc}{\contentsline {subsubsection}{Tipi di apprendimento}{15}{}\protected@file@percent }
\citation{r.AID.ologist}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces Tipi di apprendimento. Con l'apprendimento supervisionato, il numero di input (immagini TC in questo esempio) è uguale al numero di obiettivi (stato di malignità di una lesione qui). Con semi-supervisionato, il numero di input è maggiore del numero di obiettivi (il set di dati include campioni non etichettati). Con l'apprendimento non supervisionato, nessuno degli input viene etichettato (ad esempio, clustering, apprendimento multiplo, macchine di Boltzmann limitate). N.A. indica informazioni non disponibili\relax }}{16}{}\protected@file@percent }
\newlabel{fig:type-of-learning}{{2.5}{16}}
\citation{montagnon2020deep}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.3}Conclusioni}{17}{}\protected@file@percent }
\citation{towards:demandForecast}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Demand forecasting}{18}{}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Overview}{18}{}\protected@file@percent }
\citation{mobidev:demandForecast}
\citation{mobidev:demandForecast}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Workflow}{19}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Raccolta dati}{19}{}\protected@file@percent }
\citation{makridakis2018statistical}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}Comprensione e preelaborazione dei dati}{20}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Parametri di qualità dei dati}{20}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Preelaborazione dei dati}{20}{}\protected@file@percent }
\citation{cox1955some}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.3}Costruzione del modello}{21}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Esempio di suddivisione dei dati\relax }}{22}{}\protected@file@percent }
\newlabel{fig:data-split-forecast}{{3.1}{22}}
\@writefile{toc}{\contentsline {subsubsection}{Perceptron multistrato (MLP)}{22}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Rete neurale bayesiana (BNN)}{23}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Reti neurali di regressione generalizzata (GRNN)}{24}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Regressione K-Nearest Neighbor (KNN)}{25}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Regressione del vettore di supporto (SVR)}{25}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Rete Neurale Ricorrente (RNN)}{26}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Rete neurale di memoria a lungo termine (LSTM)}{26}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.4}Formazione del modello}{27}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.5}Validazione del modelllo}{27}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.6}Miglioramento}{27}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.7}Distribuzione}{28}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Analisi e conclusioni}{28}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.1}I dati}{28}{}\protected@file@percent }
\citation{kilimci2019improved}
\citation{makridakis2018statistical}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.2}Il modello}{30}{}\protected@file@percent }
\citation{towards:demandForecast}
\citation{makridakis2018statistical}
\citation{makridakis2018statistical}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.3}Conclusioni}{32}{}\protected@file@percent }
\citation{MetaFLow}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Frameworks}{33}{}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}MetaFlow}{33}{}\protected@file@percent }
\citation{MetaFLow}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Esempio di addestramento di due versioni di un modello in parallelo e scelta di quella con il punteggio più alto\relax }}{34}{}\protected@file@percent }
\newlabel{fig:ex-MetaFlow}{{4.1}{34}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.1}Vantaggi}{34}{}\protected@file@percent }
\citation{ZenML}
\citation{ZenML}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}ZenML}{35}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}Problemi risolti da ZenML}{35}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces Pipeline con ZenML\relax }}{36}{}\protected@file@percent }
\newlabel{fig:ZenML-schema}{{4.2}{36}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.2}Vantaggi}{36}{}\protected@file@percent }
\citation{MLRun}
\citation{MLRun}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}MLRun}{37}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces architettura di MLRun\relax }}{37}{}\protected@file@percent }
\newlabel{fig:MLRun}{{4.3}{37}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.1}Vantaggi}{37}{}\protected@file@percent }
\citation{MLRun}
\newlabel{code:MLRun-code}{{4.1}{38}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {4.1}Esempio di codice}{38}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces MLRun Dashbord\relax }}{39}{}\protected@file@percent }
\newlabel{fig:MLRun-dashbord}{{4.4}{39}}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Conclusioni}{40}{}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {chapter}{Appendices}{42}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {.1}Recurrent neural network}{43}{}\protected@file@percent }
\newlabel{appendix:RNN}{{.1}{43}}
\@writefile{toc}{\contentsline {section}{\numberline {.2}Convolutional neural network}{43}{}\protected@file@percent }
\newlabel{appendix:CNN}{{.2}{43}}
\@writefile{toc}{\contentsline {section}{\numberline {.3}Long-Short Term Memory}{43}{}\protected@file@percent }
\newlabel{appendix:LSTM}{{.3}{43}}
\citation{itwiki:123095653}
\@writefile{toc}{\contentsline {section}{\numberline {.4}Gated Recurrent Units (GRU)}{44}{}\protected@file@percent }
\newlabel{appendix:GRU}{{.4}{44}}
\@writefile{toc}{\contentsline {section}{\numberline {.5}Natural language processing (NLP)}{44}{}\protected@file@percent }
\newlabel{appendix:NLP}{{.5}{44}}
\@writefile{toc}{\contentsline {section}{\numberline {.6}Neuro-linguistic programming (PNL)}{44}{}\protected@file@percent }
\newlabel{appendix:PNL}{{.6}{44}}
\@writefile{toc}{\contentsline {section}{\numberline {.7}Power Trasformation (Box-Cox)}{44}{}\protected@file@percent }
\newlabel{appendix:Box-Cox}{{.7}{44}}
\citation{itwiki:119581182}
\@writefile{toc}{\contentsline {section}{\numberline {.8}Docker}{45}{}\protected@file@percent }
\newlabel{appendix:Docker}{{.8}{45}}
\@writefile{toc}{\contentsline {section}{\numberline {.9}Kubernetes}{45}{}\protected@file@percent }
\newlabel{appendix:Kubernetes}{{.9}{45}}
\@writefile{toc}{\contentsline {section}{\numberline {.10}Exponential Smoothing di Holt Winter}{45}{}\protected@file@percent }
\newlabel{appendix:ETS}{{.10}{45}}
\@writefile{toc}{\contentsline {section}{\numberline {.11}ARIMA/SARIMA}{45}{}\protected@file@percent }
\newlabel{appendix:ARIMA}{{.11}{45}}
\@writefile{toc}{\contentsline {section}{\numberline {.12}Root-mean-square deviation (RMSD)}{46}{}\protected@file@percent }
\newlabel{appendix:RMSD}{{.12}{46}}
\@writefile{toc}{\contentsline {section}{\numberline {.13}Mean absolute percentage error (MAPE)}{46}{}\protected@file@percent }
\newlabel{appendix:MAPE}{{.13}{46}}
\bibstyle{plain}
\bibdata{Bibliography}
\@writefile{toc}{\contentsline {section}{\numberline {.14}DICOM}{47}{}\protected@file@percent }
\newlabel{appendix:DICOM}{{.14}{47}}
\@writefile{toc}{\contentsline {section}{\numberline {.15}PACS}{47}{}\protected@file@percent }
\newlabel{appendix:PACS}{{.15}{47}}
\bibcite{r.AID.ologist}{1}
\bibcite{banerjee2019comparative}{2}
\bibcite{cox1955some}{3}
\bibcite{kilimci2019improved}{4}
\bibcite{makridakis2018statistical}{5}
\bibcite{MLRun}{6}
\bibcite{mobidev:demandForecast}{7}
\bibcite{montagnon2020deep}{8}
\bibcite{MetaFLow}{9}
\bibcite{pennington2014glove}{10}
\bibcite{towards:demandForecast}{11}
\bibcite{singh2019chest}{12}
\bibcite{itwiki:123095653}{13}
\bibcite{itwiki:119581182}{14}
\bibcite{ZenML}{15}
\bibcite{zhang2018learning}{16}
\gdef \@abspage@last{50}
